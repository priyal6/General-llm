# -*- coding: utf-8 -*-
"""slm2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vVoWx3ghSiE2TNDOmRpQV0uSXcCtsea9
"""

!pip install bitsandbytes

pip install -U bitsandbytes

from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

model_id = "google/flan-t5-base"

tokenizer = AutoTokenizer.from_pretrained(model_id)
model = AutoModelForSeq2SeqLM.from_pretrained(model_id)

text = "Summarize: Large language models are neural networks trained on vast amounts of text."
inputs = tokenizer(text, return_tensors="pt")

output = model.generate(**inputs, max_new_tokens=60)
print(tokenizer.decode(output[0], skip_special_tokens=True))

from sentence_transformers import SentenceTransformer
import numpy as np

model = SentenceTransformer("all-MiniLM-L6-v2")

docs = [
    "Transformers are neural networks",
    "Cats are animals",
    "Machine learning is fun"
]

embeddings = model.encode(docs)
query = model.encode("What is a transformer model?")

scores = np.dot(embeddings, query)
print(scores)